{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from make_dir import mkdir\n",
    "from load_yaml import get_yaml\n",
    "\n",
    "import models.net as solutions\n",
    "import equations.poisson_eqn as equation\n",
    "\n",
    "from dataset import Sampler\n",
    "import solver as solver \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config\n",
    "current_path = os.path.abspath(\".\")\n",
    "yaml_path = os.path.join(current_path, \"config.yaml\")\n",
    "Config = get_yaml(yaml_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dimension = Config[\"physical_config\"][\"space_dimension\"]\n",
    "d_in = space_dimension\n",
    "layers = Config[\"model_config\"][\"units\"]\n",
    "\n",
    "# build neural networks for f\n",
    "Model = \"solutions.Model_\" + \\\n",
    "    \"{}\".format(Config[\"model_config\"][\"neural_network_type\"])\n",
    "Model = eval(Model)\n",
    "\n",
    "# approx theta and phi with neural networks\n",
    "model = Model(input_size = d_in, layers = layers, output_size = 1)\n",
    "\n",
    "device_ids = Config[\"model_config\"][\"device_ids\"]\n",
    "device = torch.device(\"cuda:{:d}\".format(device_ids[0]) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.device_count() > 1:    \n",
    "    model = nn.DataParallel(model, device_ids = device_ids)\n",
    "    \n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of paramerters\n",
    "param_num = sum(neural.numel() for neural in model.parameters())\n",
    "print(\"Number of paramerters for networks is: {:6d}. \".format(param_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions.Xavier_initi(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set optimizer and learning rate decay\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.parameters()},\n",
    "],  lr=Config[\"model_config\"][\"lr\"])\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(\n",
    "    optimizer, Config[\"model_config\"][\"stage_num\"], Config[\"model_config\"][\"decay_rate\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc89aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sol = model\n",
    "eqn = equation.Poisson(config = Config, sol = Sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iter = Config[\"model_config\"][\"iterations\"] \n",
    "regularizers = Config[\"model_config\"][\"regularizers\"]\n",
    "\n",
    "loss_record, error_record = np.array([[]]).T, np.array([[]]*1).T\n",
    "\n",
    "mkdir(file_dir = \"./model_saved\")\n",
    "mkdir(file_dir = \"./record\")\n",
    "mkdir(file_dir = \"./figure\")\n",
    "\n",
    "time_start = time.time()\n",
    "print('Begin training.')\n",
    "print('')\n",
    "for it in range(Iter):\n",
    "    \n",
    "    sampler = Sampler(Config)\n",
    "    trainloader = [sampler.interior(),]\n",
    "        \n",
    "    risk, error = solver.train_step(sol = Sol,\n",
    "                                    trainloader = trainloader, \n",
    "                                    equation = eqn,  \n",
    "                                    regularizers = regularizers,\n",
    "                                    optimizer = optimizer, \n",
    "                                    scheduler = scheduler)\n",
    "    \n",
    "    loss = risk[\"total_loss\"]\n",
    "    res_eqn = risk[\"eqn\"]\n",
    "    res_bc = risk[\"bc\"]\n",
    "    error_u = error[\"u\"]\n",
    "\n",
    "    error = np.array([error_u], dtype=float).reshape(1, -1)\n",
    "    loss_record = np.concatenate((loss_record, loss*np.ones((1, 1))), axis=0)\n",
    "    error_record = np.concatenate((error_record, error), axis=0)\n",
    "\n",
    "    lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "    \n",
    "        print(\"[Iter: {:6d}/{:6d} - lr: {:.2e} and Loss: {:.2e}]\".format(it + 1, Iter, lr, loss))\n",
    "        print(\"[Error for u: {:.2e}]\".format(float(error[:, 0])))\n",
    "        print(\"[Eqn: {:.2e}, Boundary: {:.2e}]\".format(res_eqn, res_bc))\n",
    "\n",
    "np.savez(\"./record/result.npz\",\n",
    "         loss=loss_record,\n",
    "         error=error_record[:, 0])\n",
    "\n",
    "solutions.save_param(model, path = './model_saved/model_params.pkl')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Finished training.\")\n",
    "time_end = time.time()\n",
    "print(\"Total time is: {:.2e}\".format(time_end - time_start), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6e4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298dfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d5869e11385f44a167fd3d2cdea0e1e5c43dad84bdba40735d97de09139fbff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
